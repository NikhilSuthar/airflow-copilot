{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udf31 Welcome to Airflow\u202fCopilot","text":"<p>A conversational AI assistant that lets you run, monitor, and manage Apache Airflow directly from Microsoft Teams \u2014 powered by LLMs and the Airflow REST API.</p> <p></p>"},{"location":"#what-is-airflow-copilot","title":"\u2728 What is Airflow Copilot?","text":"<p>Airflow Copilot bridges the gap between orchestration and conversation. It enables teams to:</p> <ul> <li>\ud83d\udde3\ufe0f Interact with Airflow using natural language inside Microsoft Teams</li> <li>\ud83d\udd01 Trigger and monitor DAGs, tasks, schedules</li> <li>\ud83e\udde0 Leverage LLMs (OpenAI, Google, Anthropic, Groq)</li> <li>\ud83d\udd12 Enforce RBAC-based access control</li> <li>\ud83d\udcda Preserve memory via LangGraph checkpoints in PostgreSQL</li> </ul>"},{"location":"#ready-to-begin","title":"\ud83d\udea6 Ready to Begin?","text":"<p>\ud83d\udca1 Follow the Quick Start and get your Copilot up &amp; running in less than 10 minutes.</p> \ud83d\udd39 Section \ud83d\udd17 Link \ud83d\udccc Why Visit? \ud83d\ude80 Quick Start Get Started \u2192 Two-file Docker setup for local testing \ud83d\udee0\ufe0f Architecture How it Works \u2192 High-level design &amp; component workflow \u2699\ufe0f Configuration Env Variables \u2192 All runtime settings at a glance \ud83d\udce6 Deployment Deploy Options \u2192 Local, Docker Prod, Kubernetes, AWS \ud83e\udd16 Agent Behavior Smart Logic \u2192 Fallbacks, retries, limitations \u2764\ufe0f Contributing Join Me \u2192 Help build the future of Copilot"},{"location":"#features-overview","title":"\ud83e\uddf0 Features Overview","text":"<ul> <li>\ud83d\udd04 Chat-driven orchestration of DAGs, variables, tasks, and runs</li> <li>\ud83e\udde0 LLM-powered intelligence via OpenAI, Gemini, Claude, Groq</li> <li>\ud83d\udd10 Role-aware execution with Airflow RBAC integration</li> <li>\ud83e\udde9 Persistent memory stored via LangGraph + PostgreSQL</li> <li>\ud83c\udf0d Unified deployment: Docker Compose \u2192 Kubernetes \u2192 ECS</li> </ul>"},{"location":"#try-it-out","title":"\ud83e\uddea Try It Out","text":"<p>\ud83d\udee0\ufe0f Follow the Quick Start \u2192 chat with your DAGs in Microsoft Teams.  </p>"},{"location":"#lets-build-together","title":"\ud83e\udd1d Let\u2019s Build Together","text":"<p>Airflow Copilot is fully open source. We welcome your ideas, tools, feedback, and pull requests.</p> <p>\ud83d\udc49 View the Roadmap \u00b7 Contribute</p> <p>\ud83d\ude80 Automate smarter. Collaborate better. That\u2019s Copilot.</p>"},{"location":"contributing/","title":"\ud83e\udd1d Contributing to Airflow Copilot","text":"<p>We welcome contributions of all kinds \u2014 new tools, bug fixes, documentation improvements, and more. Follow the steps below to get started:</p>"},{"location":"contributing/#development-workflow","title":"\ud83d\udee0\ufe0f Development Workflow","text":"<ol> <li> <p>Fork the Repository    \u2192 Create a feature branch using the convention: <code>feat/your-feature-name</code></p> </li> <li> <p>Run Code Quality Checks    Ensure your code passes pre-commit hooks and style checks:    <pre><code>pre-commit run -a\n</code></pre></p> <p>Includes: <code>black</code>, <code>isort</code>, <code>flake8</code>, and <code>mypy</code>.</p> </li> <li> <p>Run Tests    Make sure all tests pass before opening a PR:    <pre><code>pytest -q\n</code></pre></p> </li> <li> <p>Open a Pull Request    Submit your PR and make sure all CI checks pass. Use a clear title and description. Link related issues if applicable.</p> </li> </ol>"},{"location":"contributing/#tips","title":"\ud83d\udca1 Tips","text":"<ul> <li>Small, focused PRs are easier to review.</li> <li>Write meaningful commit messages.</li> <li>Add tests for new features or bug fixes when possible.</li> <li>For major features, consider opening a discussion or issue first.</li> </ul> <p>Thanks for helping improve Airflow Copilot! \ud83d\ude80</p>"},{"location":"roadmap/","title":"\ud83d\udd2d Product Roadmap","text":"<p>This page outlines the upcoming features and long-term vision for Airflow Copilot. While the current version offers powerful orchestration capabilities via Microsoft Teams, several enhancements are actively being explored to make the assistant more intelligent, proactive, and versatile.</p>"},{"location":"roadmap/#planned-enhancements","title":"\ud83e\udde0 Planned Enhancements","text":""},{"location":"roadmap/#1-tooling-optimization","title":"1. \ud83d\udd27 Tooling Optimization","text":"<p>Improve the performance and accuracy of existing tools used by the AI agent\u2014especially around error handling, fallback mechanisms, and dynamic Airflow version support.</p>"},{"location":"roadmap/#2-redis-support-as-copilot-backend","title":"2. \ud83d\uddc4\ufe0f Redis Support as Copilot Backend","text":"<p>Introduce Redis as an optional backend for storing Copilot state, checkpoints, and intermediate responses. This addition aims to:</p> <ul> <li>Enhance performance for high-concurrency environments.</li> <li>Reduce latency during message summarization and session context recall.</li> <li>Support distributed deployments with better scalability.</li> <li>Serve as an alternative to PostgreSQL for ephemeral state tracking.</li> </ul> <p>\ud83d\udca1 Redis will be especially useful in stateless serverless deployments or scenarios where conversation history doesn't need long-term persistence.</p>"},{"location":"roadmap/#3-multi-channel-communication","title":"3. \ud83d\udce1 Multi-Channel Communication","text":"<p>Expand Copilot\u2019s availability to support other messaging platforms beyond Microsoft Teams (e.g., Slack, Discord, Webchat). This ensures greater accessibility for users across teams and infrastructures.</p>"},{"location":"roadmap/#4-proactive-monitoring-user-driven","title":"4. \ud83d\udd14 Proactive Monitoring (User-Driven)","text":"<p>Introduce intent-based monitoring. Example:</p> <p>\u201cCopilot, monitor <code>my_dag</code> tonight and notify me if it fails.\u201d</p> <p>Copilot will intelligently track execution outcomes and proactively notify the user based on specific instructions.</p>"},{"location":"roadmap/#5-email-notification-integration","title":"5. \u2709\ufe0f Email Notification Integration","text":"<p>Enable direct email support for DAG status updates, alerts, and action confirmations. This allows users to receive updates even outside their chat interface.</p>"},{"location":"roadmap/#6-allow-per-user-llm-key-and-model","title":"6. \ud83d\udd11 Allow per user LLM Key and Model","text":"<p>Currently the LLM Key is centralised that can be bottelneck for some case so plan it to provide deployment as BYOK (Bring you own Key).</p>"},{"location":"roadmap/#have-a-feature-request","title":"\ud83d\udca1 Have a Feature Request?","text":"<p>I'd love to hear from you! Feel free to open a GitHub issue or suggest improvements via your preferred channel.</p> <p>\u2139\ufe0f Note: Roadmap items are subject to change based on user feedback, platform limitations, and emerging use cases. Stay tuned for updates!</p>"},{"location":"architecture/agent/","title":"\ud83e\udd16 Agent Workflow","text":"<p>Airflow Copilot uses a LangGraph-based, tool\u2011driven agent to transform plain\u2011language conversations into secure and auditable Airflow API calls.</p> <p></p> <p>\ud83e\udded\u00a0Each user message flows through summarization (if needed), model reasoning, and tool execution via LangGraph.</p>"},{"location":"architecture/agent/#workflow-overview","title":"\ud83d\udd01 Workflow Overview","text":"<p>Every user message flows through the following loop:</p> Step Node Purpose 1\ufe0f\u20e3 Summarize Condenses earlier messages into a short summary to keep context lightweight (see Summarization) 2\ufe0f\u20e3 Model\u00a0Call The LLM decides whether to respond directly or invoke one or more tools 3\ufe0f\u20e3 Tool\u00a0Node Executes one or more Airflow tools asynchronously and returns results \ud83d\udd04 Conditional Edge If tool calls remain, loops back to Tool Node; otherwise, finalizes the user response \u2705 END Delivers the natural\u2011language reply or tool output to the user"},{"location":"architecture/agent/#state-management","title":"\ud83d\udce6 State Management","text":"<p>LangGraph maintains conversation history across sessions and redeployments using persistent checkpoints stored in PostgreSQL.</p> <ul> <li>Thread ID \u2014 Each user conversation is tracked using their Microsoft Teams ID.</li> <li>Summarization \u2014 Older messages are trimmed into concise summaries (3\u20134 lines) to reduce input length. Note: messages are logically removed from state, but still stored in the backend.</li> <li>PostgreSQL Checkpointer \u2014 Persists state transitions after every model/tool interaction, enabling recovery from crashes and safe concurrency.</li> </ul>"},{"location":"architecture/agent/#tool-execution-flow","title":"\ud83d\udee0\ufe0f Tool Execution Flow","text":"<ol> <li>The LLM generates tool calls like <code>get_all_dags</code>, <code>trigger_dag</code>, etc.</li> <li>The Tool Node handles each tool call:</li> <li>Extracts and builds the full API request (<code>url</code>, <code>method</code>, <code>payload</code>)</li> <li>Resolves credentials (centralized or per-user)</li> <li>Makes the HTTP request via httpx (asynchronously with retries)</li> <li>Returns the response content</li> <li>If no additional tool calls remain, the agent composes and sends the final natural\u2011language message.</li> </ol>"},{"location":"architecture/agent/#supported-llm-providers","title":"\ud83c\udf0d Supported LLM Providers","text":"<p>Airflow Copilot is LLM-agnostic \u2014 just configure the appropriate environment variables, and the agent loads the correct SDK at runtime:</p> Provider Env Prefix Example Model OpenAI <code>OPENAI_</code> <code>gpt-4o</code> Google GenAI <code>GOOGLE_GENAI_</code> <code>gemini-pro</code> Anthropic <code>ANTHROPIC_</code> <code>claude-3-opus</code> <p>You can use one provider for core reasoning, and another for summarization or low-cost background tasks.</p>"},{"location":"architecture/agent/#key-advantages","title":"\u26a1 Key Advantages","text":"<ul> <li>Concurrency\u2011Friendly: Async architecture and Postgres checkpointer support many Teams users at once.</li> <li>Lightweight Context: Smart summarization keeps LLM input compact and relevant.</li> <li>Tool Security: The LLM is limited to a predefined set of tools\u2014it cannot invent or manipulate endpoints.</li> </ul>"},{"location":"architecture/agent/#next-steps","title":"\ud83d\udd17\u00a0Next Steps","text":"<ul> <li>Message Summarization: Understand the Agent workflow.</li> <li>Supported Airflow Copilot Features: List of activity Airflow copilot can do.</li> <li>Environment Variables: Configration details of Airflow Copilot.</li> </ul>"},{"location":"architecture/airflow_auth_type/","title":"\ud83d\udd10 Airflow Auth Type","text":"<p>Airflow Copilot supports two authentication strategies to interact securely with Apache Airflow:</p> <ul> <li>centralized</li> <li>per_user</li> </ul> <p>By default, per_user authentication is enabled, which restricts unauthorized access and provides user-specific credential validation.</p>"},{"location":"architecture/airflow_auth_type/#centralized-authentication","title":"\ud83d\udee0\ufe0f Centralized Authentication","text":"<p>In centralized mode, a common set of Airflow credentials is used for all users. These credentials are passed during deployment and remain fixed unless the service is redeployed.</p> <p>\u2705 Recommended for: small teams with shared access rights  \u26a0\ufe0f Avoid this setup if users require role-based or restricted access.</p>"},{"location":"architecture/airflow_auth_type/#configuration","title":"\ud83d\udd27 Configuration","text":"<p>Set the following environment variables during deployment:</p> <pre><code>AIRFLOW_AUTH_STRATEGY=centralized\nAIRFLOW_USER_NAME=&lt;airflow username&gt;\nAIRFLOW_USER_PASSWORD=&lt;airflow password&gt;\n</code></pre>"},{"location":"architecture/airflow_auth_type/#design","title":"Design","text":"<ul> <li>All users share the same access level.</li> <li>If credentials change, you must update the deployment or restart the container.</li> </ul>"},{"location":"architecture/airflow_auth_type/#per-user-authentication","title":"\ud83d\udc64 Per-User Authentication","text":"<p>With <code>per_user</code> auth type, each user can securely store their Airflow credentials using the Microsoft Teams interface.</p> <ul> <li>Credentials are stored in PostgreSQL with Fernet encryption \u2014 same as Airflow\u2019s default encryption method.</li> <li>Ensures users only access resources they are authorized for.</li> </ul> <p>\u2705 Recommended for: enterprises, teams with multiple roles, or fine-grained access control.</p>"},{"location":"architecture/airflow_auth_type/#configuration_1","title":"\ud83d\udd27 Configuration","text":"<pre><code>AIRFLOW_AUTH_STRATEGY=per_user\nAIRFLOW_USER_NAME=\nAIRFLOW_USER_PASSWORD=\n</code></pre> <p>\ud83d\udcdd Note: Leave <code>AIRFLOW_USER_NAME</code> and <code>AIRFLOW_USER_PASSWORD</code> blank \u2014 credentials are set by each user individually through the Microsoft Teams UI.</p>"},{"location":"architecture/airflow_auth_type/#design_1","title":"Design","text":"<p>-- - All users share their own credential. - If credential change for any user, he/she can change it directly using MS Team Prompt.</p> <p></p>"},{"location":"architecture/airflow_auth_type/#how-users-can-set-their-airflow-credentials","title":"\ud83e\udded How Users Can Set Their Airflow Credentials","text":"<p>Open Microsoft Teams and find the Airflow Copilot bot.</p> <p>Type the following command (case insensitive):</p> <p><code>Update my Airflow Credential</code></p> <p>The bot will display a secure input form asking for:</p> <ul> <li>Username</li> <li>Password</li> </ul> <p>Upon submission, the bot:</p> <ul> <li>\ud83d\udd10 Encrypts and stores the credentials</li> <li>\u2705 Validates them by calling <code>GET /dags</code> on your Airflow instance</li> </ul>"},{"location":"architecture/airflow_auth_type/#visual-aid","title":"\ud83d\uddbc\ufe0f Visual Aid","text":"<p>A screenshot here helps users visualize the workflow and credential setup process.</p> <p></p>"},{"location":"architecture/airflow_auth_type/#next-steps","title":"\ud83d\udd17\u00a0Next Steps","text":"<ul> <li>Message Summarization: Understand the Agent workflow.</li> <li>Supported Airflow Copilot Features: List of activity Airflow copilot can do.</li> <li>Environment Variables: Configration details of Airflow Copilot.</li> <li>Refresh History: How to delete/purge user conversation with Airflow copilot from backend database(postgres)</li> <li>Supported Airflow Copilot Features: List of activity Airflow copilot can do.</li> </ul>"},{"location":"architecture/architecture/","title":"\ud83c\udfd7\ufe0f Airflow Copilot Architecture","text":""},{"location":"architecture/architecture/#overview","title":"Overview","text":"<p>Airflow Copilot is designed to bridge Microsoft Teams with Apache Airflow, enabling conversational orchestration of DAGs and metadata management through a chatbot interface. It leverages Azure Bot Services, a LangGraph-based AI Agent, and native Airflow REST APIs to carry out intelligent, context-aware operations.</p> <p></p> <p>The above diagram represents the standard deployment architecture of Airflow Copilot. All components inside the dotted box can be deployed locally or on the cloud.</p> <p>On cloud environments, the system can run as a single Dockerized application or be designed using serverless architecture principles.</p> <p>Refer to the Deployment section for environment-specific setup details.</p>"},{"location":"architecture/architecture/#components","title":"\ud83d\udd01 Components","text":"Component Description Microsoft Teams The user interface where individuals interact with the Copilot chatbot. Airflow Copilot Bot Custom chatbot app hosted on the Microsoft Teams framework. Azure Bot Service Routes messages securely via HTTPS to the registered bot webhook. Bot API Layer The FastAPI application that receives messages and triggers agent logic. Bot Adapter Bridges communication between the API layer and the AI Agent. Airflow Copilot Agent LangGraph-based agent that handles stateful conversations and tool logic. PostgreSQL Persists conversation state and user metadata. Apache Airflow The orchestrator under automation, accessed via its native REST API."},{"location":"architecture/architecture/#network-topology","title":"\ud83c\udf10 Network Topology","text":"Direction Protocol Source Target Description Inbound HTTPS Azure Bot Service FastAPI Webhook Delivers user activity to the Airflow Copilot backend. Internal Local FastAPI (Bot API Layer) Bot Adapter Normalizes messages and state for the agent. Internal LangGraph Bot Adapter Airflow Copilot Agent Executes conversation flow and tools via LangGraph. Outbound HTTPS Airflow Copilot Tools Apache Airflow REST API Triggers DAGs, retrieves logs, manages metadata/configs."},{"location":"architecture/architecture/#security","title":"\ud83d\udd12 Security","text":"<ul> <li>Azure Bot Identity: Manages secure identity and session routing via Microsoft.</li> <li>Encrypted HTTPS Webhook: All communication between Teams and the bot is encrypted.</li> <li>Credential Encryption: Per-user Airflow credentials are encrypted using a Fernet key and stored securely in PostgreSQL.</li> <li>Access Control: Supports both centralized and per-user credential modes to enforce fine-grained access control on Airflow.</li> </ul>"},{"location":"architecture/architecture/#deployment-flexibility","title":"\ud83d\udd04 Deployment Flexibility","text":"<ul> <li>\ud83d\udcbb Local development supported via ngrok for HTTPS tunneling.</li> <li>\ud83d\udc33 One-step Docker Compose setup for FastAPI, PostgreSQL, and optional Airflow container.</li> <li>\u2601\ufe0f Compatible with Azure, AWS, GCP, or any Kubernetes / VM deployment model.</li> <li>\ud83d\udce1 Easily extensible to Slack, Web App UIs, or other messaging platforms via the Bot Adapter.</li> </ul>"},{"location":"architecture/architecture/#project-structure","title":"\ud83d\udcc2 Project Structure","text":"File/Module Description <code>docker-compose.yml</code> Container-based deployment entry point <code>settings.py</code> Central config manager with env + encryption logic <code>airflow_tools.py</code> Tool layer for interacting with Airflow API <code>graph.py</code> LangGraph logic for chat orchestration <code>README.md</code> Project documentation index"},{"location":"architecture/architecture/#next-steps","title":"\ud83d\udd17\u00a0Next Steps","text":"<ul> <li>Agent workflow: Understand the Agent workflow.</li> <li>Message Summarization: Understand the Agent workflow.</li> <li>Supported Airflow Copilot Features: List of activity Airflow copilot can do.</li> </ul> <p>\ud83d\udca1 Pro Tip: To fully unlock the agent's capabilities, pair it with summarization, memory retention, and message pruning for production-scale deployments.</p>"},{"location":"architecture/refresh_history/","title":"\ud83d\uddd1\ufe0f\u202fRefresh\u202fHistory","text":"<p>Airflow\u202fCopilot stores every chat message in a PostgreSQL check\u2011pointer so the agent can resume conversations. Although messages are summarised for the LLM, they still accumulate in the database and can eventually consume storage.</p> <p>The \u201cRefresh History\u201d prompt lets a user wipe their own conversation records, keeping the backend lean without touching shared data or credentials.</p>"},{"location":"architecture/refresh_history/#why-refresh-history","title":"\ud83d\udd0d\u202fWhy Refresh History?","text":"Reason Benefit \ud83e\uddf9 Reduce database bloat Frees disk space and keeps query performance high. \ud83d\udd12 Privacy / Compliance Users can remove sensitive chat content on demand. \ud83d\udca1 Clean slate Start a new conversation thread without prior history. \ud83d\udca1 New Start Conversation start accumulating again when user interect with Bot."},{"location":"architecture/refresh_history/#what-gets-deleted","title":"\u2699\ufe0f\u202fWhat Gets Deleted?","text":"Item Deleted? Conversation messages (<code>user messages</code> &amp; <code>ai message</code>) Yes Per\u2011user Airflow credentials (<code>credentials</code> table, per_user auth) No Global settings, logs, audit records No <p>\u26a0\ufe0f\u202fOnly the user\u2019s own chat records are removed. Other users\u2019 data is untouched.</p>"},{"location":"architecture/refresh_history/#how-to-refresh-history","title":"\ud83d\udee0\ufe0f\u202fHow to Refresh History?","text":"<ol> <li>Open Microsoft\u202fTeams and chat with Airflow\u202fCopilot.  </li> <li>Type the command (case\u2011insensitive): <code>Refresh History</code></li> <li>The bot will prompt for confirmation:  \u201cClear Chat History?\u201d</li> <li>Click Refresh &amp; Save Space.  </li> <li>Copilot replies\u202f \u201c\ud83c\udf3f History cleaned!Thanks for keeping things green and speedy!\u201d</li> </ol>"},{"location":"architecture/refresh_history/#security-notes","title":"\ud83d\udd10\u202fSecurity Notes","text":"<ul> <li>Credentials are preserved \u2013 users do not need to re\u2011enter Airflow username / password after a history wipe.</li> <li>Only the requesting user can delete their own history.</li> </ul>"},{"location":"architecture/refresh_history/#best-practice","title":"\u2705\u202fBest Practice","text":"<ul> <li>Run the cleanup Every day when the conversation end. (e.g., after certain task).</li> <li>Administrators can automate bulk purges with SQL if required. Truncate all tables except <code>user_credentials</code> table.</li> <li>For long\u2011lived conversations, rely on Summarization to keep the LLM context short, and use Refresh History to manage storage footprint.</li> </ul>"},{"location":"architecture/refresh_history/#next-steps","title":"\ud83d\udd17\u00a0Next Steps","text":"<ul> <li>Supported Airflow Copilot Features: List of activity Airflow copilot can do.</li> <li>Airflow Auth Type: Airflow Auth type supported to authentication.</li> <li>Environment Variables: Configration details of Airflow Copilot.</li> </ul>"},{"location":"architecture/summarization/","title":"\ud83e\udde0 Summarization Logic","text":"<p>Airflow Copilot uses a background summarization mechanism to intelligently compress long chat histories into concise summaries. This ensures the LLM\u2019s context window remains optimized while still preserving essential historical intent and behavior.</p>"},{"location":"architecture/summarization/#why-summarization-is-needed","title":"\ud83d\udd0d Why Summarization Is Needed","text":"<p>Modern LLMs have strict token limits, and exceeding those limits leads to:</p> <ul> <li>\u274c Truncated prompts  </li> <li>\u26a0\ufe0f Incomplete or lost context  </li> <li>\ud83e\udde0 Reduced memory of earlier user requests and responses </li> <li>\ud83d\udcb0 More messages = higher cost \u2014 especially with large or chatty conversations</li> </ul> <p>To mitigate this, Airflow Copilot trims older messages into concise summaries after a certain threshold \u2014 while preserving the most recent interactions verbatim.</p>"},{"location":"architecture/summarization/#how-summarization-works","title":"\ud83e\udded How Summarization Works","text":"<p>Each time the message count exceeds a configured threshold, the earliest interactions are summarized and replaced with a compact summary entry.</p> <p></p> <p>Summarization replaces verbose chat history with a condensed version while keeping the latest messages intact.</p>"},{"location":"architecture/summarization/#design-notes","title":"\ud83d\udee1\ufe0f Design Notes","text":"<p>\u2705 Messages are not deleted from the database \u2014 only trimmed from in-memory state. \u2728 Summaries are maintained in a separate key: <code>state[\"summary\"]</code>. \ud83d\udd01 Summarization is triggered automatically when the total message count exceeds <code>MIN_MSG_TO_SUMMARIZE + MIN_MSG_TO_RETAIN</code>. \ud83d\udd0d Last human message before the cutoff is preserved, ensuring summarization doesn't split active interactions or commands. </p>"},{"location":"architecture/summarization/#tuning-parameters","title":"\ud83e\uddea Tuning Parameters","text":"<p>Control summarization behavior through the following environment variables:</p> Variable Description Default <code>MIN_MSG_TO_SUMMARIZE</code> Minimum messages required before summarization kicks in <code>10</code> <code>MIN_MSG_TO_RETAIN</code> Number of recent messages to retain without summarizing <code>10</code> <p>\ud83d\udca1 This only affects runtime memory. To fully delete stored messages, see the Delete History section. \u26a0\ufe0f Avoid setting the values too low \u2014 this may lead to excessive summarization and increased LLM usage. \u2705 Recommended: use a lightweight or cost-effective model for summarization.</p>"},{"location":"architecture/summarization/#benefits","title":"\ud83e\udde0 Benefits","text":"<ul> <li>\u2705 Keeps LLM context window small and efficient  </li> <li>\ud83e\udde0 Preserves conversation continuity in compressed form  </li> <li>\ud83d\udeab Prevents token overflow for long or technical sessions  </li> <li>\ud83d\udd04 Enables smooth, reliable, long-running conversations  </li> </ul>"},{"location":"architecture/summarization/#example-airflow-dag-interaction","title":"\ud83d\udcac Example: Airflow DAG Interaction","text":"<p>Let\u2019s walk through a typical conversation and how it might be summarized:</p>"},{"location":"architecture/summarization/#full-interaction-before-summarization","title":"\ud83d\udde8\ufe0f Full Interaction Before Summarization","text":"<p>Prior Summary: None  </p> <p>Human: Hello</p> <p>AI: Calling greet tool...</p> <p>Tool Call: <code>greet(user_name='John')</code></p> <p>AI: Hello John, how can I assist you with Airflow?</p> <p>Human: Can you show me the latest DAG runs for <code>load_sales_data</code>?</p> <p>AI: <code>call get_dag_runs tool with dag id 'load_sales_data'</code></p> <p>Tool Call: <code>get_dag_runs(dag_id='load_sales_data')</code></p> <p>AI: Here are the last 3 DAG runs: - <code>run_2024_06_01</code> \u2013 \u2705 Success - <code>run_2024_06_02</code> \u2013 \u274c Failed - <code>run_2024_06_03</code> \u2013 \u2705 Success</p> <p>Human: Please retry the failed run.</p> <p>AI: Retrying <code>run_2024_06_02</code> for DAG <code>load_sales_data</code>.</p> <p>Tool Call: <code>trigger_dag(dag_id='load_sales_data', dag_run_id='run_2024_06_02')</code></p> <p>AI: The failed DAG has been triggered.</p>"},{"location":"architecture/summarization/#after-summarization","title":"\ud83e\uddfe After Summarization","text":"<p>Summarization: The user, John, initiated a greeting and requested the latest DAG runs for <code>load_sales_data</code>. The assistant retrieved three recent runs, identifying <code>run_2024_06_02</code> as failed. Upon user request, that run was successfully re-triggered through the API.</p>"},{"location":"architecture/summarization/#interaction-after-summarization","title":"\ud83d\udde8\ufe0f Interaction After Summarization","text":"<p>Prior Summary: The user, John, initiated a greeting and requested the latest DAG runs for <code>load_sales_data</code>. The assistant retrieved three recent runs, identifying <code>run_2024_06_02</code> as failed. Upon user request, that run was successfully re-triggered through the API.</p> <p>Human: Can you tell me if the DAG ran successfully?</p> <p>AI: Yes, the DAG <code>load_sales_data</code> has run successfully. The current status is <code>Success</code>, and the run ID is <code>run_2024_06_02</code>.</p> <p>\ud83d\udca1 In the above conversation, the copilot did not ask for <code>dag_id</code> or <code>dag_run_id</code> again \u2014 it inferred those from the summary context.</p> <p>Without summarization, the next LLM call would include all 13 messages (12 from previous interactions + 1 new user message).</p> <p>With summarization, the same context is preserved using just 2 messages: the summary and the new user message \u2014 resulting in a significant token and cost reduction.</p>"},{"location":"architecture/summarization/#final-note","title":"\ud83d\udccc Final Note","text":"<p>Summarization is completely transparent to the user. It\u2019s designed to:</p> <ul> <li>\u2705 Optimize performance  </li> <li>\ud83e\udde0 Prevent model context loss  </li> <li>\ud83d\udd01 Maintain long conversation continuity  </li> </ul> <p>Even across hundreds of exchanges, Airflow Copilot remains context-aware, memory-efficient, and responsive.</p>"},{"location":"architecture/summarization/#next-steps","title":"\ud83d\udd17\u00a0Next Steps","text":"<ul> <li>Refresh History: How to delete/purge user conversation with Airflow copilot from backend database(postgres)</li> <li>Supported Airflow Copilot Features: List of activity Airflow copilot can do.</li> <li>Airflow Auth Type: Airflow Auth type supported to authentication.</li> <li>Environment Variables: Configration details of Airflow Copilot.</li> </ul>"},{"location":"architecture/supported_apis/","title":"\ud83c\udfcb\ufe0f Supported Capabilities","text":"<p>Airflow Copilot is designed to assist with informational and on-demand operations in Apache Airflow. It enables users to query metadata, trigger DAGs, inspect task details, and more \u2014 all without directly accessing the Airflow UI.</p> <p>Security-first Design: Airflow Copilot does not support deletion of DAGs to avoid accidental or unauthorized changes. Instead, it allows you to disable (pause) a DAG to prevent it from running.</p> <p>DAG Trigger Convention: Any DAG run initiated by Copilot uses a <code>genai_</code> prefix in the <code>dag_run_id</code>, making it easy to identify which runs were triggered by the assistant.</p> <p>The following sections provide a categorized summary of what you can do with Airflow Copilot via Microsoft Teams or API integration.</p>"},{"location":"architecture/supported_apis/#dags","title":"DAGs","text":"<ul> <li>Get all dags</li> <li>Get dag information</li> <li>Get dag details</li> <li>Enable dag</li> <li>Disable dag</li> <li>Trigger dag</li> <li>Get dag runs</li> <li>Get specific dag run</li> <li>Update dag state</li> <li>Update dag run note</li> <li>Get dag source code</li> <li>Get dag run</li> <li>List all dag runs</li> <li>Get dag warning</li> </ul>"},{"location":"architecture/supported_apis/#tasks","title":"Tasks","text":"<ul> <li>Get tasks</li> <li>Get task details</li> <li>Get task instances</li> <li>List task instances in dag run</li> <li>Get task instance</li> <li>Update task instances</li> <li>Get task log url</li> </ul>"},{"location":"architecture/supported_apis/#variables","title":"Variables","text":"<ul> <li>List variables</li> <li>Get variable</li> <li>Set variable</li> </ul>"},{"location":"architecture/supported_apis/#connections","title":"Connections","text":"<ul> <li>List connections</li> <li>Get connection</li> <li>Update connection</li> </ul>"},{"location":"architecture/supported_apis/#pools","title":"Pools","text":"<ul> <li>List pools</li> <li>Get pool</li> <li>Create pool</li> <li>Update pool</li> </ul>"},{"location":"architecture/supported_apis/#roles-and-permissions","title":"Roles and Permissions","text":"<ul> <li>List permissions</li> <li>List roles</li> <li>Get role</li> <li>Create role</li> <li>Update role</li> </ul>"},{"location":"architecture/supported_apis/#users","title":"Users","text":"<ul> <li>List users</li> <li>Get user</li> <li>Create user</li> <li>Update user</li> </ul>"},{"location":"architecture/supported_apis/#xcoms","title":"XComs","text":"<ul> <li>List xcoms for task</li> <li>Get xcom</li> </ul>"},{"location":"architecture/supported_apis/#logs","title":"Logs","text":"<ul> <li>List event logs</li> <li>Get event logs</li> <li>Get task log url</li> </ul>"},{"location":"architecture/supported_apis/#system-info","title":"System Info","text":"<ul> <li>Get info</li> <li>Get config</li> <li>Get health</li> <li>Get version</li> </ul>"},{"location":"architecture/supported_apis/#plugins-providers","title":"Plugins &amp; Providers","text":"<ul> <li>List plugins</li> <li>List providers</li> </ul>"},{"location":"architecture/supported_apis/#import-errors","title":"Import Errors","text":"<ul> <li>List import error</li> <li>Get import error</li> </ul>"},{"location":"architecture/supported_apis/#datasets","title":"Datasets","text":"<ul> <li>List datasets</li> <li>List dataset triggered dags</li> </ul>"},{"location":"architecture/supported_apis/#next-steps","title":"\ud83d\udd17\u00a0Next Steps","text":"<ul> <li>Agent Behavior Notes &amp; Known Limitations: Some know Airflow Copilot behaviour and Limitations.</li> </ul>"},{"location":"architecture/supported_apis/#next-steps_1","title":"\ud83d\udd17\u00a0Next Steps","text":"<ul> <li>Refresh History: How to delete/purge user conversation with Airflow copilot from backend database(postgres)</li> <li>Airflow Auth Type: Airflow Auth type supported to authentication.</li> <li>Environment Variables: Configration details of Airflow Copilot.</li> </ul>"},{"location":"configuration/environment_variables/","title":"\u2699\ufe0f Airflow Copilot \u2013 Environment Configuration","text":"<p>This document describes all the environment variables required for running Airflow Copilot, including their purpose, default values, and behavior across different authentication strategies.</p>"},{"location":"configuration/environment_variables/#core-configuration","title":"\ud83e\udde0 Core Configuration","text":"Variable Description Required Default <code>LLM_MODEL_PROVIDER_NAME</code> The name of the LLM provider (e.g., <code>openai</code>, <code>google_genai</code>) \u2705 \u2013 <code>LLM_MODEL_NAME</code> The specific model to use (e.g., <code>gpt-4</code>, <code>mixtral-8x7b</code>) \u2705 \u2013 <code>{PROVIDER}_API_KEY</code> API key used to authenticate with the selected LLM provider \u2705 \u2013 <code>DB_URI</code> PostgreSQL URI for persisting agent state and user data \u2705 \u2013 <code>MICROSOFT_APP_ID</code> Azure Bot App registration ID \u2705 \u2013 <code>MICROSOFT_APP_PASSWORD</code> Secret/password for the registered bot \u2705 \u2013 <ul> <li><code>{PROVIDER}_API_KEY</code>- Replace the {PROVIDER} with the  LLM_MODEL_PROVIDER_NAME (in Uppercase). For example , OPENAI_API_KEY or GOOGLE_GENAI_API_KEY etc.</li> </ul>"},{"location":"configuration/environment_variables/#summarization-configuration","title":"\ud83e\uddfe Summarization Configuration","text":"Variable Description Required Default <code>SUMMARIZATION_LLM_MODEL_PROVIDER_NAME</code> LLM provider to use specifically for summarization (fallbacks to core provider if unset) \u274c Provider above <code>SUMMARIZATION_LLM_MODEL_NAME</code> LLM model name for summarization (fallbacks to core model if unset) \u274c Model above <code>SUMMARIZATION_LLM_MODEL_KEY</code> LLM model key for summarization (fallbacks to core model if unset) \u274c above key <code>MIN_MSG_TO_RETAIN</code> Minimum messages to keep before summarizing earlier messages \u2705 5 <code>MIN_MSG_TO_SUMMARIZE</code> Minimum messages required (beyond retained) to trigger summarization \u2705 5"},{"location":"configuration/environment_variables/#airflow-authentication","title":"\ud83d\udd10 Airflow Authentication","text":"Variable Description Required Default <code>AIRFLOW_AUTH_STRATEGY</code> Defines credential strategy: <code>centralized</code> or <code>per_user</code> \u2705 <code>per_user</code>"},{"location":"configuration/environment_variables/#centralized-strategy","title":"Centralized Strategy","text":"Variable Description Required <code>AIRFLOW_BASE_URL</code> Base URL of your Apache Airflow instance \u2705 <code>AIRFLOW_USER_NAME</code> Global user for calling Airflow APIs \u2705 <code>AIRFLOW_USER_PASSWORD</code> Password for the global Airflow user \u2705"},{"location":"configuration/environment_variables/#per-user-strategy","title":"Per User Strategy","text":"Variable Description Required <code>FERNET_SECRET_KEY</code> Secret key used for encrypting user credentials in the DB \u2705"},{"location":"configuration/environment_variables/#variable-for-local-deployment","title":"Variable for Local Deployment","text":"Variable Description Required <code>AZURE_BOT_NAME</code> Name of the Bot that you have created. e.g Airflow-Copilot \u2705 <code>NGROK_AUTHTOKEN</code> NGROK Auth Token \u2705"},{"location":"configuration/environment_variables/#environment-variable-details","title":"\ud83d\udd0d Environment Variable Details","text":"<ol> <li> <p><code>LLM_MODEL_PROVIDER_NAME</code> </p> <ul> <li>Description: Name of the LLM provider responsible for AI/agent interactions.  </li> <li>Default: None </li> <li>Possible values: <code>openai</code>, <code>google_genai</code>, <code>anthropic</code>.  </li> <li>Required: \u2705 Yes  </li> </ul> </li> <li> <p><code>LLM_MODEL_NAME</code> </p> <ul> <li>Description: The LLM model used for primary reasoning and responses.  </li> <li>Default: None </li> <li>Possible values: <code>gpt-4</code>, <code>mixtral-8x7b</code>, <code>gemini-pro</code>, etc.  </li> <li>Required: \u2705 Yes  </li> </ul> </li> <li> <p><code>{PROVIDER}_API_KEY</code> </p> <ul> <li>Description: API key used to authenticate with the selected LLM provider. Replace <code>{PROVIDER}</code> with the uppercase value of <code>LLM_MODEL_PROVIDER_NAME</code>.  </li> <li>Default: None </li> <li>Possible values: Varies by provider  </li> <li>Required:                                                                      </li> </ul> </li> <li> <p><code>DB_URI</code>         - Description: PostgreSQL URI used for persisting state, conversation checkpoints, and user credentials.         - Default: None         - Possible values: e.g., <code>'postgresql://username:password@host:port/db'</code>         - Required: \u2705 Yes  </p> </li> <li> <p><code>MICROSOFT_APP_ID</code> </p> <ul> <li>Description: Azure Bot registration ID. Required to connect your bot to Microsoft Teams.  </li> <li>Default: None </li> <li>Possible values: Azure-generated GUID  </li> <li>Required: \u2705 Yes  </li> </ul> </li> <li> <p><code>MICROSOFT_APP_PASSWORD</code> </p> <ul> <li>Description: Secret associated with the Azure Bot App ID.  </li> <li>Default: None </li> <li>Possible values: Azure-generated client secret  </li> <li>Required: \u2705 Yes  </li> </ul> </li> <li> <p><code>SUMMARIZATION_LLM_MODEL_PROVIDER_NAME</code> </p> <ul> <li>Description: Optional override for the LLM provider used in summarization. Falls back to the main provider if not set.  </li> <li>Default: value of <code>LLM_MODEL_PROVIDER_NAME</code> </li> <li>Possible values: Same as LLM providers  </li> <li>Required: \u274c Optional  </li> </ul> </li> <li> <p><code>SUMMARIZATION_LLM_MODEL_NAME</code> </p> <ul> <li>Description: Optional override for the model used in summarization. Falls back to main model if not set.  </li> <li>Default: value of <code>LLM_MODEL_NAME</code> </li> <li>Possible values: Same as other models  </li> <li>Required: \u274c Optional  </li> </ul> </li> <li> <p><code>MIN_MSG_TO_RETAIN</code> </p> <ul> <li>Description: Number of most recent user/tool messages to retain in memory before summarization.  </li> <li>Default: <code>10</code> </li> <li>Possible values: Integer &gt; 0  </li> <li>Required: \u2705 Yes  </li> </ul> </li> <li> <p><code>MIN_MSG_TO_SUMMARIZE</code> </p> <ul> <li>Description: Minimum number of messages beyond retained ones to trigger summarization.  </li> <li>Default: <code>10</code> </li> <li>Possible values: Integer &gt; 0  </li> <li>Required: \u2705 Yes  </li> </ul> </li> <li> <p><code>AIRFLOW_AUTH_STRATEGY</code> </p> <ul> <li>Description: Defines how Airflow credentials are managed \u2013 centrally or per user.  </li> <li>Default: <code>per_user</code> </li> <li>Possible values: <code>centralized</code>, <code>per_user</code> </li> <li>Required: \u2705 Yes  </li> </ul> </li> <li> <p><code>AIRFLOW_BASE_URL</code> </p> <ul> <li>Description: Base URL of the Airflow instance used for API calls.  </li> <li>Default: None </li> <li>Possible values: e.g., <code>https://&lt;host&gt;:&lt;port&gt;</code> </li> <li>Required: \u2705 Yes  </li> </ul> </li> <li> <p><code>AIRFLOW_USER_NAME</code> </p> <ul> <li>Description: Username for Airflow (only for centralized strategy).  </li> <li>Default: None </li> <li>Possible values: Any valid Airflow user  </li> <li>Required: \u2705 Yes (if <code>centralized</code>)  </li> </ul> </li> <li> <p><code>AIRFLOW_USER_PASSWORD</code> </p> <ul> <li>Description: Password for Airflow user (only for centralized strategy).  </li> <li>Default: None </li> <li>Possible values: Any valid password  </li> <li>Required: \u2705 Yes (if <code>centralized</code>)  </li> </ul> </li> <li> <p><code>FERNET_SECRET_KEY</code> </p> <ul> <li>Description: Encryption key used to store user-specific Airflow credentials in the database.  </li> <li>Default: None </li> <li>Possible values: Base64-encoded 32-byte key  </li> <li>Required: \u2705 Yes (if <code>per_user</code>) </li> <li>Command: Run below command to generate the key.</li> </ul> </li> </ol> <pre><code>python -c \"from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())\"\n</code></pre> <p>Do not change the Farnet key in every deployment otherwise the backend credentials will not be decrypt and every user have to update their cred again.</p> <ol> <li> <p><code>AZURE_BOT_NAME</code></p> <ul> <li>Description: The Azure Bot Name to automatically update the endpoint while Local Deployment.  </li> <li>Default: Airflow-Copilot </li> <li>Required: No </li> </ul> </li> <li> <p><code>NGROK_AUTHTOKEN</code></p> <ul> <li>Description: The Ngrok Token to deploy the Local Fast API to public Https endpoint.  </li> <li>Required: \u2705 Yes (for Local deployment) </li> </ul> </li> </ol>"},{"location":"configuration/environment_variables/#notes","title":"\ud83d\udcdd Notes","text":"<ul> <li> <p>The <code>.env</code> file is auto-created if missing at <code>src/.env</code>.</p> </li> <li> <p>You can dynamically update the environment file via:</p> </li> </ul>"},{"location":"deployment/deployment/","title":"\ud83d\ude80 Airflow Copilot \u2014 Deployment Modes Overview","text":"<p>This guide compares the three deployment options for Airflow Copilot:</p> <ol> <li>\ud83e\uddea Local Development (Docker + Ngrok)</li> <li>\ud83e\uddf1 Docker-based Production Deployment</li> <li>\u2601\ufe0f Kubernetes-based Cloud Deployment</li> </ol> <p>Note: The following sections assume you\u2019ve already completed Azure Bot creation and installed the Copilot app in Microsoft Teams.</p> <p>All options use the same <code>.env</code> file format for managing environment variables.</p>"},{"location":"deployment/deployment/#comparison-table","title":"\ud83d\udcca Comparison Table","text":"Aspect Local (Dev) Docker (Prod) Kubernetes (Prod) Deployment Method Docker Compose Docker Compose Kubernetes YAML manifests Public Access Ngrok Tunnel Reverse Proxy (e.g., NGINX) Ingress / LoadBalancer + DNS Bot Endpoint Setup Auto-patched via <code>update_bot.sh</code> Manual or scripted Manual or scripted PostgreSQL Host or Container DB (ephemeral) External DB (e.g., RDS) Cloud-hosted DB or StatefulSet TLS/HTTPS Via Ngrok Setup via NGINX TLS via cert-manager Secrets Management <code>.env</code> file <code>.env</code> file Kubernetes Secrets Scaling Not applicable Manual HPA or KEDA Logging &amp; Monitoring Local stdout Volume/log driver Centralized (ELK / Prometheus / Grafana)"},{"location":"deployment/deployment/#prepare-environment-variables","title":"\ud83d\udee0 Prepare Environment Variables","text":"<p>All deployment types rely on a single <code>.env</code> file. </p> <code>.env</code> <pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 LLM (pick ONE provider) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nLLM_MODEL_PROVIDER_NAME=OpenAI\nLLM_MODEL_NAME=gpt-4o\nOPENAI_API_KEY=your-openai-api-key\n\n# Google example:\n# LLM_MODEL_PROVIDER_NAME=Google_Genai\n# LLM_MODEL_NAME=gemini-2.5-flash\n# GOOGLE_GENAI_API_KEY=ai-...\n\n# Anthropic example\n# LLM_MODEL_PROVIDER_NAME=Anthropic\n# LLM_MODEL_NAME=claude-3-5-sonnet-20240620\n# ANTHROPIC_API_KEY=ai-...\n\n# Groq example\n# LLM_MODEL_PROVIDER_NAME=Groq\n# LLM_MODEL_NAME=groq-1\n# GROQ_API_KEY=ai-...\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Azure Bot / Service Principal \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nMICROSOFT_APP_ID=your-bot-id\nMICROSOFT_APP_PASSWORD=bot-secret\nAZURE_CLIENT_ID=your-client-id\nAZURE_BOT_NAME=your-bot-name # e.g., Airflow-Copilot\nAZURE_CLIENT_SECRET=your-spn-secret\nAZURE_TENANT_ID=your-tenant-id\nRESOURCE_GROUP=your-resource-group\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Airflow REST API \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nAIRFLOW_BASE_URL=your-airflow-url # e.g., http://localhost:8080/\nAIRFLOW_AUTH_STRATEGY=per_user # default is 'per_user', can also be 'centralized'\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Postgres connection \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Pass Airflow Postgres connection string here if you are using same postgres for Airflow and Copilot\n# If you are using a different Postgres instance, update the connection string accordingly.\n# Example:\n# DB_USER=airflow\n# DB_PASSWORD=airflow\n# DB_HOST=host.docker.internal\n# DB_PORT=5432  \nDB_URI=postgresql://&lt;your-db-user&gt;:&lt;your-db-password&gt;@&lt;your-db-host&gt;:&lt;your-db-port&gt;/&lt;your-db-name&gt;\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Misc \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nFERNET_SECRET_KEY=your-fernet-secret-key # Generate using: python -c \"from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())\"\nMIN_MSG_TO_RETAIN=10 #default is 10\n# Minimum number of messages to retain in the conversation history before summarization\nMIN_MSG_TO_SUMMARIZE=10 #default is 10\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Summarization LLM \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSUMMARIZATION_LLM_MODEL_PROVIDER_NAME=OpenAI # or OpenAI, Anthropic, Google_Genai\nSUMMARIZATION_LLM_MODEL_NAME=gpt-4o # or gpt-4o, claude-3-5-sonnet\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Optional \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# If you want to use ngrok for local development, set your ngrok authtoken\nNGROK_AUTHTOKEN=your-ngrok-authtoken # Optional, if you want to use ngrok for local development\n</code></pre>"},{"location":"deployment/deployment/#1-local-deployment-docker-ngrok","title":"1\ufe0f\u20e3 Local Deployment (Docker + Ngrok)","text":"<ul> <li>Recommended for development and testing.</li> <li>Ngrok exposes a public endpoint for Microsoft Teams.</li> <li>The <code>bot-updater</code> service automatically updates the Azure Bot messaging endpoint using Azure Service Principal.</li> </ul>"},{"location":"deployment/deployment/#architecture","title":"Architecture","text":""},{"location":"deployment/deployment/#steps","title":"Steps:","text":"<ul> <li>Follow the full  Getting Started guide.</li> </ul>"},{"location":"deployment/deployment/#2-docker-based-production-deployment","title":"2\ufe0f\u20e3 Docker-Based Production Deployment","text":"<ul> <li>Uses the same Copilot Docker image, but with a hardened <code>.env</code>.</li> <li>A reverse proxy like NGINX is used to expose the service over TLS.</li> <li>PostgreSQL must be externally hosted (e.g., RDS, Cloud SQL).</li> <li>Azure Bot messaging endpoint must be updated manually.</li> </ul>"},{"location":"deployment/deployment/#prerequisites-docker-production","title":"Prerequisites (Docker Production)","text":"<p>In addition to the general requirements listed earlier, the following components are essential for deploying Airflow Copilot in a production environment using Docker Compose:</p> <ol> <li>Apache Airflow Instance </li> <li> <p>A running Airflow instance (version \u2265 2.5.0) with the REST API enabled and accessible to Copilot.</p> </li> <li> <p>Persistent PostgreSQL Database </p> </li> <li> <p>A reliable PostgreSQL instance (self-hosted or managed, e.g., AWS RDS, Azure DB) to store conversation history and LangGraph checkpoints.</p> </li> <li> <p>Reverse Proxy (e.g., NGINX or Traefik) </p> </li> <li>Required to securely expose FastAPI (/api/messages) over HTTPS.  </li> </ol> <p>\ud83d\udca1 You may also want to integrate with a certificate manager like Let's Encrypt for automatic HTTPS.</p>"},{"location":"deployment/deployment/#architecture_1","title":"Architecture","text":""},{"location":"deployment/deployment/#steps_1","title":"Steps:","text":"<ol> <li> <p>Prepare <code>.env</code> file: Populate your <code>.env</code> file with required values. Skip any variables that used only in local mode. Reference Environment Variables</p> </li> <li> <p>Create <code>docker-compose.prod.yml</code></p> <p> <code>docker-compose.prod.yml</code> docker-compose.prod.yml<pre><code># docker-compose.prod.yml  \u2013\u00a0production stack\nversion: \"3.9\"\n\n# \u2500\u2500\u2500\u2500\u2500 reusable anchor that mounts the real secrets file \u2500\u2500\u2500\u2500\u2500\nx-env: &amp;envfile\n  env_file: .env            # \u2190 use your populated .env (not .env.example)\n\nnetworks:\n  airflow: {}\n\nservices:\n  copilot:\n    image: thedatacarpenter/airflow-copilot:latest\n    container_name: copilot\n    &lt;&lt;: *envfile\n    ports:\n      - \"3978:3978\"\n\n    environment:\n      # -------- LLM (choose ONE provider in .env) --------\n      LLM_MODEL_PROVIDER_NAME: ${LLM_MODEL_PROVIDER_NAME}\n      LLM_MODEL_NAME:          ${LLM_MODEL_NAME}\n\n      # Provider\u2011specific keys (only one will be used by Copilot)\n      OPENAI_API_KEY:          ${OPENAI_API_KEY}\n      GOOGLE_GENAI_API_KEY:    ${GOOGLE_GENAI_API_KEY}\n      # GROQ_API_KEY:            ${GROQ_API_KEY}\n      # ANTHROPIC_API_KEY:       ${ANTHROPIC_API_KEY}\n\n      # Summarisation (leave empty to let the app fall back internally)\n      SUMMARIZATION_LLM_MODEL_PROVIDER_NAME: ${SUMMARIZATION_LLM_MODEL_PROVIDER_NAME}\n      SUMMARIZATION_LLM_MODEL_NAME:          ${SUMMARIZATION_LLM_MODEL_NAME}\n\n      # -------- Thresholds --------\n      MIN_MSG_TO_SUMMARIZE: ${MIN_MSG_TO_SUMMARIZE:-10}\n      MIN_MSG_TO_RETAIN:    ${MIN_MSG_TO_RETAIN:-10}\n\n      # -------- Airflow --------\n      AIRFLOW_AUTH_STRATEGY: ${AIRFLOW_AUTH_STRATEGY:-centralized}\n      AIRFLOW_BASE_URL:      ${AIRFLOW_BASE_URL}\n      AIRFLOW_USER_NAME:     ${AIRFLOW_USER_NAME}\n      AIRFLOW_USER_PASSWORD: ${AIRFLOW_USER_PASSWORD}\n\n      # -------- Database --------\n      DB_URI: ${DB_URI}\n\n      # -------- Azure Bot --------\n      MICROSOFT_APP_ID:       ${MICROSOFT_APP_ID}\n      MICROSOFT_APP_PASSWORD: ${MICROSOFT_APP_PASSWORD}\n\n      # -------- Security --------\n      FERNET_SECRET_KEY: ${FERNET_SECRET_KEY}\n\n    depends_on: [db-init]\n    networks: [airflow]\n\n  # one\u2011shot Postgres schema bootstrap\n  db-init:\n    image: postgres:16\n    &lt;&lt;: *envfile\n    entrypoint: [\"/bin/bash\", \"/init_db.sh\"]\n    environment:\n      DB_URI: ${DB_URI}\n    volumes:\n      - ./docker/scripts/init_db.sh:/init_db.sh:ro\n      - ./docker/scripts/init.sql:/init.sql:ro\n    restart: \"no\"\n    networks: [airflow]\n</code></pre> </p> </li> <li> <p>Start Services</p> <p><pre><code># Create Docker network (once)\ndocker network create airflow\n\n# Start all services\ndocker compose -f docker-compose.prod.yml up -d\n</code></pre> 4. Expose via Reverse Proxy: </p> <p>Configure NGINX or similar to route <code>https://copilot.yourdomain.com/api/messages \u2192 http://copilot:3978</code>.  Then update your Azure Bot endpoint in the portal:</p> <p><pre><code>    https://copilot.yourdomain.com/api/messages\n</code></pre> 5. You're Done !!!</p> </li> </ol>"},{"location":"deployment/deployment/#3-kubernetes-deployment-cloud","title":"3\ufe0f\u20e3 Kubernetes Deployment (Cloud)","text":"<ul> <li>Ideal for enterprise-scale deployments.</li> <li>Public domain and TLS managed through Ingress + cert-manager.</li> <li>Environment variables passed securely as Kubernetes Secrets.</li> </ul> <p>See: <code>production-deployment.md</code></p>"},{"location":"deployment/deployment/#prerequisites-kubernetes-production","title":"Prerequisites (Kubernetes Production)","text":"<ol> <li>Kubernetes Cluster </li> <li>A working K8s cluster (e.g., AKS, EKS, GKE, or self-hosted).  </li> <li> <p><code>kubectl</code> access with appropriate permissions to apply resources.</p> </li> <li> <p>Docker Registry Access </p> </li> <li>A container registry (e.g., Docker Hub, GHCR, ECR) to host and pull the Copilot Docker image.  </li> <li> <p>Ensure the image is pushed and accessible from within the cluster.</p> </li> <li> <p>Azure Bot App with Teams Channel </p> </li> <li>A registered Azure Bot with Microsoft App ID &amp; Password.  </li> <li> <p>The bot\u2019s messaging endpoint must point to your public Copilot Ingress URL.</p> </li> <li> <p>Cloud-hosted PostgreSQL (or StatefulSet) </p> </li> <li>A production-grade PostgreSQL instance (e.g., RDS, Cloud SQL) for storing Copilot state and summaries.  </li> <li> <p>Alternatively, deploy it as a StatefulSet inside Kubernetes with persistent volumes.</p> </li> <li> <p>Ingress Controller (e.g., NGINX) </p> </li> <li>Required to expose the Copilot FastAPI service publicly.  </li> <li> <p>Enables domain-based access and TLS termination.</p> </li> <li> <p>TLS Certificates (Recommended) </p> </li> <li>Use cert-manager with Let\u2019s Encrypt to secure your public domain via HTTPS.  </li> <li> <p>Update the Azure Bot endpoint to use the secured URL.</p> </li> <li> <p>Secrets Management </p> </li> <li>Store sensitive environment variables as Kubernetes Secrets.  </li> <li>Use sealed secrets, HashiCorp Vault, or native K8s secrets based on your security policy.</li> </ol> <p>\ud83d\udca1 All required configuration values (API keys, credentials, endpoints) should be declared in a shared <code>.env</code> file and converted to Kubernetes secrets during deployment.</p>"},{"location":"deployment/deployment/#architecture_2","title":"Architecture","text":""},{"location":"deployment/deployment/#steps_2","title":"Steps:","text":"<ol> <li> <p>Prepare Environment Variables: Create a <code>.env</code> file (as mentioned above) and populate it with the required environment variables. You may omit any variables that are specifically needed for local deployments only. For a complete reference, see Environment Variables for variable details.</p> </li> <li> <p>Generate Kubernetes Secret</p> <p><pre><code>    kubectl create namespace airflow-copilot\n    kubectl -n airflow-copilot create secret generic airflow-copilot-env --from-env-file=.env\n</code></pre> 3. Create Deployment Manifest</p> <p> <code>airflow-copilot-deployment.yaml</code> airflow-copilot-deployment.yaml<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airflow-copilot\n  namespace: airflow-copilot\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: airflow-copilot\n  template:\n    metadata:\n      labels:\n        app: airflow-copilot\n    spec:\n      containers:\n        - name: airflow-copilot\n          image: thedatacarpenter/airflow-copilot:latest\n          imagePullPolicy: IfNotPresent\n          ports:\n            - containerPort: 3978\n          envFrom:\n            - secretRef:\n                name: airflow-copilot-env\n          readinessProbe:\n            httpGet:\n              path: /ready\n              port: 3978\n            initialDelaySeconds: 5\n            periodSeconds: 10\n          livenessProbe:\n            httpGet:\n              path: /health\n              port: 3978\n            initialDelaySeconds: 15\n            periodSeconds: 10\n</code></pre> </p> </li> <li> <p>Create Ingress (Optional)</p> <p> <code>airflow-copilot-ingress.yaml</code> airflow-copilot-ingress.yaml<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: airflow-copilot-ingress\n  namespace: airflow-copilot\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\nspec:\n  tls:\n    - hosts: [\"airflow-copilot.example.com\"]\n      secretName: airflow-copilot-tls\n  rules:\n    - host: airflow-copilot.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: airflow-copilot-svc\n                port: { number: 80 }\n</code></pre> </p> </li> <li> <p>Apply All Resources</p> <p><pre><code>    kubectl apply -n airflow-copilot -f airflow-copilot-deployment.yaml\n    kubectl apply -n airflow-copilot -f airflow-copilot-service.yaml\n    kubectl apply -n airflow-copilot -f airflow-copilot-ingress.yaml\n</code></pre> 7. Update Azure Bot Endpoint Update your Azure Bot messaging endpoint to the public URL exposed via Ingress:</p> <pre><code>```url\nhttps://airflow-copilot.yourdomain.com/api/messages\n\n```\nSee [**Azure Bot Setup**](../quickstart/azure_bot.md) for more details.\n</code></pre> </li> </ol>"},{"location":"deployment/deployment/#8-youre-done","title":"8. You're Done !!!","text":""},{"location":"deployment/deployment/#deployment-summary","title":"\ud83d\udce6 Deployment Summary","text":"Mode Ideal For Public Endpoint DB Storage Local Testing/dev Ngrok Host/local Docker Small teams Reverse Proxy/Nginx Cloud DB Kubernetes Enterprise Prod DNS + TLS Ingress Managed DB"},{"location":"quickstart/agent-behavior/","title":"\ud83d\udea8 Behavior Notes &amp; Known Limitations","text":"<p>This document outlines key behavior details, recommendations, and known limitations of the Airflow Copilot agent to help you understand how it operates and what to expect during usage.</p>"},{"location":"quickstart/agent-behavior/#important-behavior-notes","title":"\ud83d\udd0d Important Behavior Notes","text":"<ul> <li> <p>Airflow Version Support:   Airflow Copilot is designed around the Airflow 2.5.1 REST API. While most functionality works across versions 2.5 to 2.11, some latest API endpoints introduced in newer versions may not be supported yet.</p> </li> <li> <p>Large API Responses &amp; Token Limits:   Airflow REST responses, especially for DAG runs and task logs, can be very large. This may cause token overflows when using models with strict limits (such as free model on <code>Groq</code>). We recommend using robust providers like OpenAI or Google AI for better handling of large responses.</p> </li> <li> <p>User Creation Behavior:   The Copilot supports creating new users and assigning roles. However, if a password is not provided, it generates one automatically. Depending on model behavior, the password may or may not be returned reliably in the response.</p> </li> <li> <p>First-Time Slowness &amp; History Refresh:   The assistant might respond slowly during initial use, especially without context. It is highly recommended to refresh history when starting a new session. Refer to Refresh History for details.</p> </li> <li> <p>Trust but Verify:   Occasionally, the AI may claim that an action (e.g., disabling a DAG) was performed, even if it wasn\u2019t successful. Always verify critical actions by asking the Copilot for confirmation (e.g., \"Is DAG <code>xyz</code> disabled?\").</p> </li> <li> <p>Message Timing:   Avoid sending multiple messages back-to-back. Wait for the assistant to respond, as it begins processing immediately after receiving input. Sending too many messages at once may confuse the context.</p> </li> <li> <p>Recommended Practice: Refresh History:   Before starting a new task or conversation, it is a good practice to refresh history so that the assistant has the relevant context available.</p> </li> </ul>"},{"location":"quickstart/agent-behavior/#known-limitations","title":"\ud83d\udeab Known Limitations","text":"<ul> <li> <p>Only Microsoft Teams as Channel Support:   Current version of copilot only support conversion through Microsoft Teams. In futher there will be more channel will be added.</p> </li> <li> <p>DAG Deletion Not Supported:   For safety reasons, Copilot does not support DAG deletion. It will recommend disabling DAGs instead.</p> </li> <li> <p>Changing DAG Schedule or Tags:   The Airflow REST API does not currently support updating DAG schedule intervals or tags. As a workaround, you can use Airflow Variables in your DAG code to define the schedule, and let Copilot update the variable value to reflect the change.</p> </li> <li> <p>Only v1 API Used:   Copilot uses only the v1 REST API. Airflow's v2 API is not yet supported.</p> </li> <li> <p>Partial Compatibility with Older Versions:   While Copilot works well with versions 2.5 to 2.11, some features may behave differently or be partially supported on older versions.</p> </li> </ul> <p>\ud83d\udcdd If you encounter inconsistent behavior, especially on older Airflow versions or with custom setups, consider submitting feedback or filing an issue to help us improve.</p>"},{"location":"quickstart/azure_bot/","title":"\ud83d\udc7e\u202fCreate an Azure\u202fBot (for Microsoft\u202fTeams)","text":"<p>Airflow\u202fCopilot communicates through a custom Microsoft\u202fTeams bot     ** hosted on Azure\u00a0Bot\u00a0Service**. Follow these steps to register the bot, enable Teams, and wire the credentials into Copilot.</p>"},{"location":"quickstart/azure_bot/#process-at-a-glance","title":"\ud83e\udded\u00a0Process at a Glance","text":"Step Action Outcome 1\ufe0f\u20e3 Register Bot in Azure\u00a0Portal Generates Microsoft\u00a0App\u00a0ID &amp; Client\u00a0Secret 2\ufe0f\u20e3 Enable Teams Channel Allows Teams users to message the bot 3\ufe0f\u20e3 Set Messaging\u202fEndpoint Points Azure\u00a0Bot \u2192 <code>https://\u2026/api/messages</code> 4\ufe0f\u20e3 Add Credentials to Copilot Copilot verifies every incoming request"},{"location":"quickstart/azure_bot/#stepbystep-guide","title":"\ud83d\udee0\ufe0f\u00a0Step\u2011by\u2011Step Guide","text":""},{"location":"quickstart/azure_bot/#1-register-the-bot","title":"1.\u00a0Register the Bot","text":"<ol> <li>Sign in to the Azure\u00a0Portal (a free\u2011tier account works fine).  </li> <li>Click \u2795\u202fCreate a resource \u2192 search \u201cAzure\u202fBot\u201d \u2192 Create.  </li> <li>Fill in the form and Click Review\u202f+\u202fCreate \u2192 Create.</li> </ol> Field Example / Notes Bot handle <code>Airflow\u2011Copilot</code> Subscription Your active subscription Resource group Create or reuse one Data residency Global (or preferred region) Pricing tier <code>F0\u202f  Free</code> (dev) or <code>S1</code> (prod) Messaging\u202fendpoint Leave blank for now"},{"location":"quickstart/azure_bot/#2-grab-app-credentials","title":"2.\u00a0Grab App Credentials","text":"<ol> <li>Open the newly\u2011created Bot\u00a0Resource.  </li> <li>Go to Settings\u00a0\u2192\u00a0Configuration.  </li> <li>Copy the values below (store them securely!):</li> </ol> <pre><code>MICROSOFT_APP_ID= 1da6ff2a-xxx-xxxx-xxxx-xxxxxxxxxxxx\nMICROSOFT_APP_PASSWORD= Csc**************************\n</code></pre> <p>Note: the client secret is shown only once after creation. Keep it safe.</p> <p></p>"},{"location":"quickstart/azure_bot/#3-enable-the-teams-channel","title":"3.\u00a0Enable the Teams Channel","text":"<ol> <li>In the left panel, choose Channels.  </li> <li>Click Microsoft\u202fTeams \u2192 Save.  </li> </ol> <p>Your bot is now reachable from Microsoft\u202fTeams\u00a0\ud83c\udf89</p> <p></p>"},{"location":"quickstart/azure_bot/#4-configure-the-messaging-endpoint","title":"4.\u00a0Configure the Messaging\u202fEndpoint","text":"Environment What to do Notes Development / Local Nothing \u2013 the Docker\u00a0Compose stack auto\u2011patches the endpoint with the current ngrok URL. Production Paste your stable HTTPS URL (e.g. <code>https://&lt;copilot.your\u2011domain.com&gt;/api/messages</code>) into Settings\u00a0\u2192\u00a0Configuration\u00a0\u2192\u00a0Messaging\u202fendpoint and click Save. Do this once after deployment or DNS cut\u2011over."},{"location":"quickstart/azure_bot/#optional-required-only-for-local-deployment","title":"\ud83d\udd10 Optional: Required Only for Local Deployment","text":"<p>When deploying Airflow Copilot locally, the bot\u2019s Messaging Endpoint (NGROK URL) get update during deployment script. This update requires authentication to Azure using a Service Principal (SPN).</p> <p>If you already have a separate service principal with Contributor access to the Azure Bot resource group, you can skip this step and use same in AZURE_CLIENT_ID and AZURE_CLIENT_SECRET in <code>docker-compose.yml</code> file. Otherwise, follow the instructions below to create one for the existing Azure Bot.</p>"},{"location":"quickstart/azure_bot/#steps-to-create-a-service-principal","title":"\ud83e\udded Steps to Create a Service Principal","text":"<ol> <li>Navigate to Microsoft Entra ID in the Azure portal.</li> <li> <p>In the left panel, select App registrations, then switch to the All applications tab.</p> <p></p> </li> <li> <p>Select your Azure Bot app from the list, then click on Create service principal.</p> <p></p> </li> <li> <p>After creating the SPN, go to Subscriptions and open the subscription associated with your Azure Bot.</p> </li> <li>Click on Access control (IAM) \u2192 \u2795 Add \u2192 Add role assignment.</li> <li>Choose Contributor from the list of roles under Privileged administrator roles.</li> <li>In the Members step, choose User, group, or service principal, then click \u2795 Select members.</li> <li>Search for and select your Bot\u2019s app registration name.</li> <li>Click Review + assign to complete the setup.</li> </ol> <p>Once completed, you can use <code>MICROSOFT_APP_ID</code> as  <code>AZURE_CLIENT_ID</code> and <code>MICROSOFT_APP_PASSWORD</code> as  <code>AZURE_CLIENT_SECRET</code>, and <code>AZURE_TENANT_ID</code> in your deployment environment.</p>"},{"location":"quickstart/azure_bot/#recap","title":"\u2705\u00a0Recap","text":"Azure output Copilot variable Purpose App\u202fID <code>MICROSOFT_APP_ID</code> Bot identity verification Client\u00a0Secret <code>MICROSOFT_APP_PASSWORD</code> JWT signing for incoming messages Teams channel \u2714\ufe0f \u2014 Enables chat from Teams to Copilot"},{"location":"quickstart/azure_bot/#security-best-practices","title":"\ud83d\udd10\u00a0Security Best Practices","text":"<ul> <li>Never hard\u2011code secrets \u2013 inject them via environment variables, Docker\u00a0Secrets, or a secrets manager.  </li> <li>Rotate the Client\u202fSecret regularly (e.g. every\u202f90\u202fdays).  </li> <li>Apply least\u2011privilege RBAC to the bot\u2019s resource group.</li> </ul>"},{"location":"quickstart/azure_bot/#next-steps","title":"\ud83d\udd17\u00a0Next Steps","text":"<ul> <li>Upload Airflow Copilot App to Microsoft Teams  : Sideload or publish Copilot in your organisation.</li> <li>Agent Behavior Notes &amp; Known Limitations: Some know Airflow Copilot behaviour and Limitations.</li> </ul>"},{"location":"quickstart/before_we_start/","title":"\ud83d\udea6\u202fPrerequisites","text":"<p>Before you spin\u2011up Airflow\u202fCopilot, make sure the following building blocks are in place.</p> <ul> <li>\u2705 Install Docker Community Edition (CE) on your workstation (based on your OS).</li> <li>\u2705 Install Docker Compose v2.14.0 or newer.</li> </ul> # Requirement Why it\u2019s needed Minimum\u202fVersion / Notes 1 Apache\u00a0Airflow Target orchestrator Copilot queries (DAG runs, tasks, variables, etc.). \u2265\u202f2.5.0 \u2022\u202fREST\u00a0API enabled 2 Azure\u202fBot\u202fService Secure webhook &amp; credentials so Microsoft\u202fTeams can talk to Copilot. Any Azure subscription \u2022\u202fConsumes Bot\u00a0Service units 3 Microsoft\u202fTeams End\u2011user chat interface. Copilot is sideloaded as a custom Teams app. Desktop / Web \u2022\u202fNot free \u201cCommunity\u201d edition 4 PostgreSQL Persists conversation state &amp; checkpoints (LangGraph). v12\u202f+ \u2022\u202fReuse Airflow DB or deploy fresh instance"},{"location":"quickstart/before_we_start/#more-context","title":"\ud83d\udcdd\u00a0More Context","text":""},{"location":"quickstart/before_we_start/#1-apache-airflow","title":"1. Apache\u202fAirflow","text":"<ul> <li>Copilot calls the native REST\u202fAPI (<code>/api/v1/...</code>).</li> <li>Airflow must be reachable from the Copilot container (or vice\u2011versa).</li> <li>Use a dedicated service account (<code>admin</code> or fine\u2011grained RBAC).</li> </ul>"},{"location":"quickstart/before_we_start/#2-azure-bot-service","title":"2. Azure\u202fBot\u202fService","text":"<ul> <li>Acts as a relay:\u00a0Teams\u202f\u21c4\u202fBot\u202fService\u202f\u21c4\u202fCopilot.</li> <li>Register a Teams Channel and paste Copilot\u2019s public webhook (ngrok / reverse proxy).</li> </ul>"},{"location":"quickstart/before_we_start/#3-microsoft-teams","title":"3. Microsoft\u202fTeams","text":"<ul> <li>Upload Copilot\u2019s <code>manifest.zip</code> via Teams Admin Center or sideload (Developer Preview).</li> <li>Free \u201cCommunity\u201d tenants do not support custom bots.</li> </ul>"},{"location":"quickstart/before_we_start/#4-postgresql","title":"4. PostgreSQL","text":"<ul> <li>Stores every message, summary &amp; checkpoint so Copilot can resume after restarts.</li> <li>Point Copilot to your existing Airflow DB or use the Docker\u2011Compose Postgres service or any persistent server database (such as RDS).</li> <li>Schema is created automatically on first run.</li> </ul>"},{"location":"quickstart/before_we_start/#5-ngrok-authtoken-optional-use-for-local-deployment-only","title":"5. Ngrok\u202fAuthtoken\u00a0(optional \u2013 use for local deployment only)","text":"<p>Need to expose Copilot\u2019s local API URL to Azure Bot? Grab your personal Ngrok authtoken:</p> <ol> <li>Sign in\u2014or create a free account\u2014at ngrok.com.</li> <li>Navigate to \u2630\u00a0\u2192\u00a0Auth\u00a0\u2192\u00a0Your\u00a0Authtoken in the sidebar.</li> <li>Copy the token and use it in your <code>docker-compose</code> file.</li> </ol>"},{"location":"quickstart/before_we_start/#next-steps","title":"\ud83d\udd17\u00a0Next Steps","text":"<ul> <li> <p>\u27a1\ufe0f Create an Azure Bot (for Microsoft Teams)   Step\u2011by\u2011step Portal &amp; CLI guide (single\u2011tenant vs multi\u2011tenant tips).</p> </li> <li> <p>\u27a1\ufe0f Upload Airflow Copilot App to Microsoft Teams   Sideload or publish Copilot to your organisation.</p> </li> </ul> <p>\ud83d\udca1\u202fTip: Run everything locally with Docker\u202fCompose for testing, then move the same containers to Kubernetes / ECS for production \u2014 just keep the environment variables consistent.</p>"},{"location":"quickstart/getting_started/","title":"\ud83d\ude80 Getting Started \u2014 Airflow Copilot","text":"<p>This guide walks you through launching  Airflow Copilot using Docker Compose files.</p>"},{"location":"quickstart/getting_started/#prerequisites","title":"\ud83e\uddf0 Prerequisites","text":"<p>Make sure you have the following ready:</p> <ul> <li>Docker \u2013 Install from Docker Docs</li> <li>Apache Airflow \u2013 Version <code>2.5.0</code> to <code>&lt; 3.0.0</code>   Use the official Docker Compose setup</li> <li>PostgreSQL \u2013 Shared between Airflow and Copilot</li> <li>Ngrok Authtoken \u2013 For public URL tunneling (local bot testing)</li> <li>Azure Bot Credentials \u2013 follow Create an Azure Bot to obtain  <ul> <li>Microsoft App\u202fID &amp; Password  </li> <li>Azure Service Principal (Client\u202fID &amp; Secret)  </li> <li>Azure Resource Group  </li> <li>Azure Tenant\u202fID</li> </ul> </li> <li>Fernet Key (32\u2011byte secret): create using below script (if not)</li> </ul> <pre><code>python -c \"from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())\"\n</code></pre> <ul> <li> <p>LLM Provider &amp; API Keys     Supported: <code>OpenAI</code>, <code>Google_GenAI</code>,  <code>Anthropic</code>, <code>Groq</code></p> <p>To get started with Google Gemini, create a free API key and use the <code>gemini-2.5-flash</code> model.</p> </li> </ul> <p>Note: This Quick Start guide covers local deployment only. For production or cloud-based deployments, refer to the Deployment section.</p>"},{"location":"quickstart/getting_started/#designconceptual","title":"\ud83e\uddea Design(conceptual)","text":"<p>Below design reflect the local deployment of the Airflow Copilot.</p> <p></p>"},{"location":"quickstart/getting_started/#step-1-launch-apache-airflow","title":"\ud83d\udee0 Step\u00a01 \u2014 Launch Apache Airflow","text":"<p>If Airflow isn\u2019t running:</p> <ol> <li>Follow\u00a0the guide: Run Airflow via Docker Compose</li> <li>Ensure Airflow and PostgreSQL are up.</li> </ol> <p>\u27a1\ufe0f Airflow UI \u2192 http://localhost:8080 \ud83d\udd10 Login \u2192 <code>admin</code> / <code>admin</code></p>"},{"location":"quickstart/getting_started/#step-2-deploy-airflow-copilot","title":"\ud83e\udd16 Step\u00a02 \u2014 Deploy Airflow Copilot","text":"<ol> <li> <p>Create a <code>.env</code> file using the template below and update all the necessary environment variables required for deployment.  </p> <p>For detailed descriptions of each variable, refer to the Environment Variables section.</p> <p> <code>.env</code> <pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 LLM (pick ONE provider) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nLLM_MODEL_PROVIDER_NAME=OpenAI\nLLM_MODEL_NAME=gpt-4o\nOPENAI_API_KEY=your-openai-api-key\n\n# Google example:\n# LLM_MODEL_PROVIDER_NAME=Google_Genai\n# LLM_MODEL_NAME=gemini-2.5-flash\n# GOOGLE_GENAI_API_KEY=ai-...\n\n# Anthropic example\n# LLM_MODEL_PROVIDER_NAME=Anthropic\n# LLM_MODEL_NAME=claude-3-5-sonnet-20240620\n# ANTHROPIC_API_KEY=ai-...\n\n# Groq example\n# LLM_MODEL_PROVIDER_NAME=Groq\n# LLM_MODEL_NAME=groq-1\n# GROQ_API_KEY=ai-...\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Azure Bot / Service Principal \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nMICROSOFT_APP_ID=your-bot-id\nMICROSOFT_APP_PASSWORD=bot-secret\nAZURE_CLIENT_ID=your-client-id\nAZURE_BOT_NAME=your-bot-name # e.g., Airflow-Copilot\nAZURE_CLIENT_SECRET=your-spn-secret\nAZURE_TENANT_ID=your-tenant-id\nRESOURCE_GROUP=your-resource-group\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Airflow REST API \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nAIRFLOW_BASE_URL=your-airflow-url # e.g., http://localhost:8080/\nAIRFLOW_AUTH_STRATEGY=per_user # default is 'per_user', can also be 'centralized'\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Postgres connection \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Pass Airflow Postgres connection string here if you are using same postgres for Airflow and Copilot\n# If you are using a different Postgres instance, update the connection string accordingly.\n# Example:\n# DB_USER=airflow\n# DB_PASSWORD=airflow\n# DB_HOST=host.docker.internal\n# DB_PORT=5432  \nDB_URI=postgresql://&lt;your-db-user&gt;:&lt;your-db-password&gt;@&lt;your-db-host&gt;:&lt;your-db-port&gt;/&lt;your-db-name&gt;\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Misc \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nFERNET_SECRET_KEY=your-fernet-secret-key # Generate using: python -c \"from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())\"\nMIN_MSG_TO_RETAIN=10 #default is 10\n# Minimum number of messages to retain in the conversation history before summarization\nMIN_MSG_TO_SUMMARIZE=10 #default is 10\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Summarization LLM \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSUMMARIZATION_LLM_MODEL_PROVIDER_NAME=OpenAI # or OpenAI, Anthropic, Google_Genai\nSUMMARIZATION_LLM_MODEL_NAME=gpt-4o # or gpt-4o, claude-3-5-sonnet\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Optional \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# If you want to use ngrok for local development, set your ngrok authtoken\nNGROK_AUTHTOKEN=your-ngrok-authtoken # Optional, if you want to use ngrok for local development\n</code></pre> </p> </li> <li> <p>Create <code>docker-compose.local.yml</code> in same <code>.env</code> folder.  </p> <p> <code>docker-compose.local.yml</code> docker-compose.local.yml<pre><code>version: \"3.9\"\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Common env-file anchor \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nx-env: &amp;envfile\n  env_file: .env  # Populate from .env or .env.local\n\nnetworks:\n  airflow:\n    driver: bridge\n\nservices:\n\n  ###########################################################################\n  # 1) Copilot \u2013 FastAPI + LangGraph agent\n  ###########################################################################\n  copilot:\n    image: ${COPILOT_IMAGE:-thedatacarpenter/airflow-copilot:latest}\n    container_name: copilot\n    &lt;&lt;: *envfile\n    restart: unless-stopped\n    ports:\n      - \"3978:3978\"\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3978/health\"]\n      interval: 10s\n      timeout: 3s\n      retries: 5\n    environment:\n      # LLM / model\n      LLM_MODEL_PROVIDER_NAME: ${LLM_MODEL_PROVIDER_NAME}\n      LLM_MODEL_NAME:          ${LLM_MODEL_NAME}\n\n      # Provider keys\n      OPENAI_API_KEY:          ${OPENAI_API_KEY}\n      GOOGLE_GENAI_API_KEY:    ${GOOGLE_GENAI_API_KEY}\n      # GROQ_API_KEY:          ${GROQ_API_KEY}\n      # ANTHROPIC_API_KEY:     ${ANTHROPIC_API_KEY}\n\n      # Thresholds\n      MIN_MSG_TO_SUMMARIZE: ${MIN_MSG_TO_SUMMARIZE:-10}\n      MIN_MSG_TO_RETAIN:    ${MIN_MSG_TO_RETAIN:-10}\n\n      # Airflow\n      AIRFLOW_AUTH_STRATEGY: ${AIRFLOW_AUTH_STRATEGY:-per_user}\n      AIRFLOW_USER_NAME:     ${AIRFLOW_USER_NAME:-airflow}\n      AIRFLOW_USER_PASSWORD: ${AIRFLOW_USER_PASSWORD:-airflow}\n      AIRFLOW_BASE_URL:      ${AIRFLOW_BASE_URL}\n\n      # Summarization model\n      SUMMARIZATION_LLM_MODEL_PROVIDER_NAME: ${SUMMARIZATION_LLM_MODEL_PROVIDER_NAME}\n      SUMMARIZATION_LLM_MODEL_NAME:          ${SUMMARIZATION_LLM_MODEL_NAME}\n\n      # Database &amp; Bot creds\n      DB_URI:                 ${DB_URI}\n      MICROSOFT_APP_ID:       ${MICROSOFT_APP_ID}\n      MICROSOFT_APP_PASSWORD: ${MICROSOFT_APP_PASSWORD}\n\n      # Security\n      FERNET_SECRET_KEY: ${FERNET_SECRET_KEY}\n    depends_on:\n      db-init:\n        condition: service_completed_successfully\n    networks: [airflow]\n\n  ###########################################################################\n  # 2) One\u2011shot schema init (external Postgres or host DB)\n  ###########################################################################\n  db-init:\n    image: postgres:16\n    &lt;&lt;: *envfile\n    entrypoint: [\"/bin/bash\", \"/init_db.sh\"]\n    restart: \"no\"\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    environment:\n      DB_URI: ${DB_URI}\n    volumes:\n      - ./docker/scripts/init_db.sh:/init_db.sh:ro\n      - ./docker/scripts/init.sql:/init.sql:ro\n    networks: [airflow]\n\n  ###########################################################################\n  # 3) Ngrok \u2013 expose local FastAPI endpoint\n  ###########################################################################\n  ngrok:\n    image: alpine:latest\n    &lt;&lt;: *envfile\n    restart: unless-stopped\n    depends_on: [copilot]\n    entrypoint: sh\n    command: -c \"\n      apk add --no-cache curl &amp;&amp; \\\n      echo '\ud83d\udd01 Waiting for Copilot...' &amp;&amp; \\\n      until curl -sf http://copilot:3978/health &gt; /dev/null; do echo '\u23f3 Waiting...'; sleep 3; done &amp;&amp; \\\n      echo '\u2705 Copilot is ready. Starting ngrok...' &amp;&amp; \\\n      curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | tee /etc/apk/keys/ngrok.asc &amp;&amp; \\\n      echo 'https://ngrok-agent.s3.amazonaws.com/alpine edge main' &gt;&gt; /etc/apk/repositories &amp;&amp; \\\n      apk add --no-cache ngrok &amp;&amp; \\\n      ngrok config add-authtoken $NGROK_AUTHTOKEN &amp;&amp; \\\n      ngrok http copilot:3978 --log stdout\"\n    ports:\n      - \"4040:4040\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:4040/api/tunnels\"]\n      interval: 5s\n      timeout: 3s\n      retries: 5\n    networks: [airflow]\n\n\n\n  ###########################################################################\n  # 4) Bot updater \u2013 patches Azure Bot with ngrok URL\n  ###########################################################################\n  bot-updater:\n    image: ${COPILOT_IMAGE:-thedatacarpenter/airflow-copilot:latest}\n    &lt;&lt;: *envfile\n    entrypoint: [\"/usr/local/bin/update_bot.sh\"]\n    depends_on:\n      ngrok:\n        condition: service_healthy\n    restart: \"no\"\n    environment:\n      NGROK_API: http://ngrok:4040/api/tunnels\n      BOT_NAME: ${AZURE_BOT_NAME:-Airflow-Copilot}\n      RESOURCE_GROUP: ${RESOURCE_GROUP}\n      AZURE_CLIENT_ID:     ${AZURE_CLIENT_ID:-${MICROSOFT_APP_ID}}\n      AZURE_TENANT_ID:     ${AZURE_TENANT_ID}\n      AZURE_CLIENT_SECRET: ${AZURE_CLIENT_SECRET:-${MICROSOFT_APP_PASSWORD}}\n    networks: [airflow]\n</code></pre> </p> </li> </ol>"},{"location":"quickstart/getting_started/#run-copilot","title":"\u25b6\ufe0f Run Copilot","text":"<pre><code># Create Docker network (once)\ndocker network create airflow\n\n# Start all services\ndocker compose -f docker-compose.local.yml up -d\n</code></pre>"},{"location":"quickstart/getting_started/#clean-up","title":"\ud83e\uddfd Clean Up","text":"<pre><code>docker compose -f docker-compose.local.yml down -v\n</code></pre>"},{"location":"quickstart/getting_started/#what-happens-next","title":"What Happens Next\u00a0\ud83c\udf89","text":"<ul> <li>Copilot launches on <code>http://localhost:3978</code> </li> <li>Ngrok exposes a public URL and the Azure bot endpoint is patched automatically  </li> <li>Chat with Airflow Copilot directly in Microsoft\u00a0Teams! Login to Azure Portal and validate the same.</li> </ul>"},{"location":"quickstart/upload_app/","title":"\ud83d\udce4 Deploying Airflow\u202fCopilot App to Microsoft Teams","text":"<p>After creating your Azure Bot, follow the steps below to connect it to the Airflow\u202fCopilot Teams app and upload the package.</p>"},{"location":"quickstart/upload_app/#1-applevel-deployment-options","title":"1: App\u2011Level Deployment Options","text":"Deployment Who can do it Visibility Organization\u2011wide Teams tenant admins Available to all users Personal scope Any user Visible only to the uploader"},{"location":"quickstart/upload_app/#2-link-the-azure-bot-to-the-teams-manifest","title":"2: Link the Azure Bot to the Teams Manifest","text":"<ol> <li> <p>Locate the Microsoft\u00a0App\u00a0ID from the Azure Bot you created earlier. (See\u00a0Create Azure Bot if you need a refresher.)</p> </li> <li> <p>Download the Copilot Teams manifest ZIP.</p> </li> <li> <p>Extract the ZIP and open <code>manifest.json</code>.</p> </li> <li> <p>Replace every instance of <code>${MICROSOFT_APP_ID}</code> with your real App\u00a0ID (usually appears twice).</p> </li> <li> <p>Re\u2011zip exactly these three files \u2014 not the folder:</p> </li> </ol> <pre><code>manifest.json\ncolor.png\noutline.png\n</code></pre>"},{"location":"quickstart/upload_app/#3-upload-the-app-to-microsoft-teams","title":"3: Upload the App to Microsoft Teams","text":"<p>Note: Uploading custom apps may be disabled on tightly\u2011managed tenants. Check with your Teams admin if the options below are missing.</p> <p>The custom app option is also not availble with community version of Microsoft Teams.</p> <ol> <li> <p>Open Microsoft Teams.</p> </li> <li> <p>Click Apps in the left sidebar.</p> </li> <li> <p>Select Manage your apps at the bottom.</p> </li> <li> <p>Click \u2795 Upload an app. Depending on your permissions you will see:</p> <ul> <li>Upload an app to your org's app catalog \u2013 Admin only  </li> <li>Upload a custom app \u2013 Personal scope  </li> <li>Submit an app to your org \u2013 Require Admin approval.</li> </ul> <p></p> </li> <li> <p>Choose the re\u2011zipped package and confirm.</p> </li> </ol> <p>Once uploaded, Airflow\u00a0Copilot will appear in your Apps list. Invite it to a channel or chat privately to start issuing Airflow commands.</p>"},{"location":"quickstart/upload_app/#next-steps","title":"\u2705 Next Steps","text":"<ul> <li>Run the Airflow Copilot</li> <li>Pin Copilot to the left rail for quick access</li> <li>Review Agent Behavior Notes for best practices</li> </ul>"}]}